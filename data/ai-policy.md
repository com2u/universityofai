ğŸ“œ AI Use Policy â€“ University of AI
Responsible Innovation. Transparent Use. Ethical AI.

ğŸ¯ Purpose of this Policy
The AI Use Policy of the University of AI ensures that the application, development, and teaching of artificial intelligence within the university follows ethical, legal, and societal standards. It applies to all students, faculty, researchers, and administrative staff.

ğŸ” Scope
This policy governs:

Development and deployment of AI systems within university projects and coursework

Usage of external AI tools (e.g., LLMs, image/audio generators, automation agents)

Data handling, model training, and publishing of AI research

Collaboration with third-party platforms and technologies involving AI

âš–ï¸ Regulatory Compliance
We comply with all applicable AI-related regulations, including:

EU AI Act (for European collaborations and research)

GDPR for personal data protection

IEEE Ethically Aligned Design principles

OECD AI Principles (transparency, accountability, robustness, human-centered values)

National standards and university-internal data policies

All AI systems or tools used within official university activities must:

Clearly document their data sources and model architecture (where applicable)

Indicate when AI-generated content is being presented

Offer human oversight where AI influences decisions

ğŸ§­ Ethical AI Guidelines
The university is committed to:

Transparency

Clearly labeling AI-generated content in educational materials, communication, and projects

Disclosing any use of automated decision systems in administrative workflows

Fairness & Non-Discrimination

Ensuring datasets used in training are curated for fairness and inclusivity

Mitigating algorithmic bias through regular audits and peer review

Accountability

Every AI project must list a responsible human lead

Student projects using autonomous systems must pass additional ethical review

Human Autonomy

AI must support, not replace, human decision-making in education and research

Students and staff retain the right to opt out of AI-mediated evaluation processes

Security

All AI tools must adhere to cybersecurity best practices

No unverified or unvetted external APIs/tools are allowed in core infrastructure

ğŸ§ª Research & Development
The University of AI encourages cutting-edge exploration, but within responsible boundaries. All AI research projects must:

Undergo an ethics check if they involve user interaction, facial recognition, biometric data, or automated decision-making

Avoid black-box deployments in critical use cases

Follow the FAIR Data Principles (Findable, Accessible, Interoperable, Reusable)

ğŸ§‘â€ğŸ“ Student Code of Conduct â€“ AI Use
Students must not:

Use generative AI to complete assignments without declaration

Use AI tools to impersonate others, generate misleading content, or bypass testing

Train models using private/unlicensed datasets without permission

Students are encouraged to:

Document their AI tools and usage in reports/presentations

Participate in ethical workshops and contribute to policy improvements

ğŸ“¢ Reporting & Oversight
Concerns or violations regarding AI use can be reported confidentially to:

AI Ethics Board
ğŸ“§ ethics@university-of-ai.edu
ğŸ›¡ï¸ Review board includes legal, technical, and ethics representatives

ğŸ¤ Continuous Improvement
This policy is updated bi-annually to reflect current technology, regulation, and research developments. Suggestions are welcome and reviewed transparently.

We donâ€™t just build AI. We build it right.
Responsibility is part of innovation.








